{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ID9xo6YybygD"
   },
   "source": [
    "## LAB 2 - TASK 2 submission. ML 2023-24.\n",
    "\n",
    "\n",
    "FILL UP THIS BOX WITH YOUR DETAILS\n",
    "\n",
    "**NAME AND NIP**: ....\n",
    "\n",
    "\n",
    "### FILL UP THIS BRIEF DESCRIPTION of your TOY DATASET:\n",
    "\n",
    "* Number of Classes: ... (typically this will be 5)\n",
    "* Name of the classes: ...\n",
    "* Source of the classes: ... (e.g., URL of original dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fySVsAP5f20w"
   },
   "source": [
    "## 2. Training from scratch\n",
    "\n",
    "In this exercise we are building a small conv net to train from scratch using Tensorflow.Keras APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xR2HfQFZkT1w"
   },
   "source": [
    "## Get data and tensorflow imports ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZKp9fe5hgarx"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QRBX1dl1hPNV"
   },
   "outputs": [],
   "source": [
    "# GET YOUR IMAGES READY\n",
    "\n",
    "# OPTION A: upload and unzip, untar ... images if necessary (not recommended ... it'll only last one session)\n",
    "#!tar -xvzf images.tar.gz\n",
    "# !unzip data.zip\n",
    "!ls\n",
    "\n",
    "# OPTION B: mount your google drive to point the code to find the data in your drive folders\n",
    "# (instructions here: https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-iPPCRFCTLRN"
   },
   "outputs": [],
   "source": [
    "# SOME HELPER FUNCTIONS TO VISUALIZE RESULTS\n",
    "def vis_history(results_history):\n",
    "    acc = results_history.history['accuracy']\n",
    "    val_acc = results_history.history['val_accuracy']\n",
    "\n",
    "    loss = results_history.history['loss']\n",
    "    val_loss = results_history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_84LSGMBMyPt"
   },
   "source": [
    "## Definning and training the CNN\n",
    "You need to train 3 versions of this model:\n",
    "* First run and train the model given here by default.\n",
    "* Then evaluate what happens if you remove Dropout layer and train again.\n",
    "* Then add code to incorporate image augmentation to the network training.\n",
    "\n",
    "Use this example to see how to easily add data augmentation as an additional layer to your model. https://www.tensorflow.org/tutorials/images/classification#data_augmentation\n",
    "\n",
    "Think what data augmentation could be interesting for your classes and program the layer to get it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zF7aizu_fmHf"
   },
   "outputs": [],
   "source": [
    "####### ***** TO-DO-LAB *****  #######\n",
    "# make sure you config these params to fit what you want/need\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "# MODIFY THE PATH TO POINT TO YOUR DATA! locally here or in your mounted drive\n",
    "data_dir = 'data/train' # all in one folder and let the system do the split\n",
    "nb_train_samples = 2000 # UPDATE WITH YOUR NUMBERS!!\n",
    "nb_validation_samples = 800 # UPDATE WITH YOUR NUMBERS!!\n",
    "epochs = 10 # 50 # UPDATE WITH YOUR NUMBERS!!\n",
    "batch_size = 4 #16\n",
    "num_classes = 5\n",
    "####### ***** TO-DO-LAB *****  #######\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2, #1\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "# for more optimized handling of the data\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "#### *************** TO-DO-LAB *************** ####\n",
    "# DEFINE a SECOND MODEL that does NOT INCLUDE DROPOUT, compile it and train it\n",
    "# model2 = ...\n",
    "#\n",
    "# DEFINE a BETTER MODEL that INCLUDES DROPOUT AND AUGMENTATION, compile it and train it\n",
    "# model3 = ...\n",
    "#### *************** END TO-DO-LAB *************** ####\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")\n",
    "\n",
    "model.save_weights('first_try.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-U6bVDfHE1nH"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCA4Goc7nmpW"
   },
   "outputs": [],
   "source": [
    "# VISUALIZE INITIAL RESULTS\n",
    "vis_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xAzfnl4CpWeI"
   },
   "outputs": [],
   "source": [
    "# PLOT HERE YOUR RESULTS WITHOUT DROPOUT\n",
    "vis_history(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "126TjJVvnECV"
   },
   "outputs": [],
   "source": [
    "# PLOT HERE YOUR RESULTS INCLUDING DROPOUT and AUGMENTATION\n",
    "vis_history(history3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YZKUnaxnP4H"
   },
   "source": [
    "### **QUESTION:** briefly discuss the results of the CNN with the different variations (with/without augmentation, with/without dropout). (maximum of 5 lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jneUV6hYndz6"
   },
   "source": [
    "ANSWER: [PUT-YOUR-ANSWER-HERE]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

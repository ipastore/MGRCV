{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gw3wgHY3ccfY"
   },
   "source": [
    "## LAB 2 - TASK 3 submission. ML 2023-24\n",
    "FILL UP THIS BOX WITH YOUR DETAILS\n",
    "\n",
    "**NAME AND NIP**: ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDutfbmfkx8_"
   },
   "source": [
    "## 3. Fine-tunning\n",
    "Now we going to fine-tune a well known CNN architecture for image classification that has already been trained in ImageNet. We are going to fine-tune this for our own toy-dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xR2HfQFZkT1w"
   },
   "source": [
    "## Get data and tensorflow imports ready\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZKp9fe5hgarx"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QRBX1dl1hPNV"
   },
   "outputs": [],
   "source": [
    "# GET YOUR IMAGES READY\n",
    "\n",
    "# OPTION A: upload and unzip, untar ... images if necessary (not recommended ... it'll only last one session)\n",
    "#!tar -xvzf images.tar.gz\n",
    "!unzip toy-data.zip\n",
    "!ls\n",
    "\n",
    "# OPTION B: mount your google drive to point the code to find the data in your drive folders\n",
    "# (instructions here: https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-iPPCRFCTLRN"
   },
   "outputs": [],
   "source": [
    "# SOME HELPER FUNCTIONS TO VISUALIZE RESULTS\n",
    "def vis_history(results_history):\n",
    "    acc = results_history.history['accuracy']\n",
    "    val_acc = results_history.history['val_accuracy']\n",
    "\n",
    "    loss = results_history.history['loss']\n",
    "    val_loss = results_history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zF7aizu_fmHf"
   },
   "outputs": [],
   "source": [
    "####### ***** TO-DO-LAB *****  #######\n",
    "# make sure you config these params to fit what you want/need to LOAD YOUR DATA\n",
    "# dimensions we will use with our images (they'll be resized if not this shape)\n",
    "img_width, img_height = 224, 224 # TO MATCH THE SIZES OF THE BASE MODEL WE WANT TO USE, MOBILENET\n",
    "# MODIFY THE PATH TO POINT TO YOUR DATA! locally here or in your mounted drive\n",
    "data_dir = 'toy-data' # all in one folder and let the system do the split\n",
    "nb_train_samples = 2000 # UPDATE WITH YOUR NUMBERS!!\n",
    "nb_validation_samples = 800 # UPDATE WITH YOUR NUMBERS!!\n",
    "batch_size = 4 #16\n",
    "num_classes = 5\n",
    "####### ***** TO-DO-LAB *****  #######\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "# for more optimized handling of the data\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVGOPJYZJTJj"
   },
   "source": [
    "## Let's do the fine-tunning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8db_o_KdI_iG"
   },
   "source": [
    "Let's load the base model, and modify the final classification layers to adapt to our 5-class toy-dataset. In this example we are fine-tuning MobileNetV2.\n",
    "\n",
    "There are plenty of base models you could use, this is a pretty good compromise quality vs speed. Many more models in: https://www.tensorflow.org/api_docs/python/tf/keras/applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Us1jvdYakxU7"
   },
   "outputs": [],
   "source": [
    "# weights = 'imagenet' is saying we want to upload the model ALREADY TRAINED in Imagenet\n",
    "# THIS IS ESSENTIAL! otherwise we will just be training the architecture from scratch\n",
    "IMG_SHAPE = (img_width, img_height) + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "\n",
    "# We use the preprocessing method included with the model (for consistency with the pre-trained model we are using)\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "# apply data augmentation\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\", input_shape=IMG_SHAPE),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")\n",
    "# let's define our last layer depending on the number of classes we want to classify\n",
    "prediction_layer = tf.keras.layers.Dense(5)\n",
    "\n",
    "# Differently from previous example, in this cases it's more convenient\n",
    "# to build our model using the Keras Model API (https://keras.io/api/models/)\n",
    "inputs = tf.keras.Input(shape=(img_width, img_height, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "# The base model contains batchnorm layers. It is ESSENTIAL TO SET IT AS inference mode\n",
    "# SO when we unfreeze the base model for fine-tuning the batchnorm information is not distroyed\n",
    "# So, we make sure that the base_model is running in inference mode here.\n",
    "# more details on this in fine-tuning tutorial: https://www.tensorflow.org/guide/keras/transfer_learning\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "print(\"Let's leave the original model frozen for now ...\")\n",
    "# FREEZE the base model\n",
    "base_model.trainable = False\n",
    "for i, layer in enumerate(model.layers):\n",
    "   print(i, layer.name, layer.trainable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XeIFQTo1-lP"
   },
   "outputs": [],
   "source": [
    "base_learning_rate = 0.001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs = 10 # UPDATE WITH YOUR NUMBERS!!\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")\n",
    "\n",
    "vis_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l3Y9gb9t1E79"
   },
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all base model layers\n",
    "print(\"And now let's enable trainable flag to the BASE MODEL: \")\n",
    "base_model.trainable = True\n",
    "for i, layer in enumerate(model.layers):\n",
    "   print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHgoYhq72gOM"
   },
   "outputs": [],
   "source": [
    "epochs = 10 # UPDATE WITH YOUR NUMBERS!!\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "history2 = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")\n",
    "vis_history(history2)\n",
    "\n",
    "# Save the model\n",
    "model.save('last_finetuned_model_V1.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IivwKiriH5yv"
   },
   "source": [
    "As a **final experiment, run a few (ONLY 2 or 3) variations to see HOW/IF your changes influence the results**.\n",
    "- You can change learning rates (where do you think it makes sense to use smaller? larger?), optimizers, batch size, ...\n",
    "- INSTEAD of just SAVING THE LAST MODEL. you can add this callback to save \"check points\" of your model (in this case is set to save only the best one found).\n",
    "More info: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\n",
    "\n",
    "You can add plenty of other \"utilities\" to run during your training process.\n",
    "More info: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3vZnK4QGUq6"
   },
   "outputs": [],
   "source": [
    "checkpoint_filepath = './tmp/checkpoint.weights.h5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "# Model weights are saved at the end of every epoch, if it's the best seen\n",
    "# so far.\n",
    "#history2 = model.fit(\n",
    "#  train_ds,\n",
    "#  validation_data=val_ds,\n",
    "#  epochs=epochs,\n",
    "#  callbacks=[model_checkpoint_callback]\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAudkgfjI438"
   },
   "source": [
    "### **QUESTION 1**. Answer True/False and explain why you think so.\n",
    "\n",
    "1. After reading the explanations in this notebook, I think when fine-tuning and existing model, we usually start with its layers frozen, but later we should un-freeze *ALL* layers always.\n",
    "\n",
    "2.   It is essential to make sure when loading the base model, its parameter *weights* are initialized to the pre-trained weigths we want, usually imagenet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzSeWbIKKf2B"
   },
   "source": [
    "ANSWER 1: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWaSnh1_Ki7o"
   },
   "source": [
    "### **QUESTION 2**.\n",
    "Discuss the results you have obtained with your toy-data after running the different steps of the fine tunning process and the variations you have incorporated.\n",
    "\n",
    "* How does it compare to the previous tasks in this Lab 3? What are advantages/disadvantages you find within each option? (max 10 lines).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0uwWgyPK4sU"
   },
   "source": [
    "ANSWER 2: [YOUR ANSWER HERE]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

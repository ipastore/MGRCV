{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports + Codebook configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "from sklearn.datasets import fetch_openml\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import  RidgeClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import rcParams\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "rcParams['figure.figsize'] = (10, 6)\n",
    "rcParams['legend.fontsize'] = 16\n",
    "rcParams['axes.labelsize'] = 16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and random printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 70000, 784\n",
      "Labels size: 70000\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "# Print the size of the data and labels\n",
    "print('Data size: %d, %d' % (X.shape[0],X.shape[1]))\n",
    "print('Labels size: %d' % (y.shape))\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "# # Show some random training samples\n",
    "# num_random_samples = 4\n",
    "# random_samples = np.random.randint(0, X.shape[0], num_random_samples)\n",
    "# for random_sample_i in random_samples:\n",
    "#     imi = X.iloc[random_sample_i,:].values.reshape(28,28)\n",
    "#     fig, ax1 = plt.subplots(1,1)\n",
    "#     figtitle = \"training image #%d\" % random_sample_i\n",
    "#     ax1.imshow(imi, cmap=plt.get_cmap('gray'))\n",
    "#     ax1.set_title(figtitle)\n",
    "#     plt.show()\n",
    "#     print('Label: %s' % (y[random_sample_i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training samples:  56700\n",
      "# validation samples:  6300\n",
      "# test samples:  7000\n"
     ]
    }
   ],
   "source": [
    "X_train_and_val, X_test, y_train_and_val, y_test = train_test_split(X, y, test_size = 0.1, random_state=5)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_and_val, y_train_and_val, test_size = 0.1, random_state=7)\n",
    "\n",
    "print('# training samples: ', X_train.shape[0])\n",
    "print('# validation samples: ', X_val.shape[0])\n",
    "print('# test samples: ', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit and transform on training data\n",
    "X_val_scaled = scaler.transform(X_val)          # Only transform on validation data\n",
    "X_test_scaled = scaler.transform(X_test)        # Only transform on test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the data should help to converge the models faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1 accuracy=94.92%, time=3.4s\n",
      "k=2 accuracy=94.24%, time=3.5s\n",
      "k=3 accuracy=94.90%, time=3.6s\n",
      "k=4 accuracy=94.70%, time=3.5s\n",
      "k=5 accuracy=94.75%, time=3.5s\n",
      "k=6 accuracy=94.49%, time=3.5s\n",
      "k=7 accuracy=94.43%, time=3.7s\n",
      "k=8 accuracy=94.29%, time=3.8s\n",
      "k=9 accuracy=94.21%, time=4.4s\n"
     ]
    }
   ],
   "source": [
    "k_neighbors = range(1, 10)\n",
    "\n",
    "for k in k_neighbors: \n",
    "    # Define a knn classifier with the training data\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Start timer to report the time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Evaluate the model with the test split and print results\n",
    "    acc_knn_clf = knn_clf.score(X_val_scaled, y_val)\n",
    "    print(f\"k={k} accuracy={acc_knn_clf * 100:.2f}%, time={time.time() - start_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different neighbors does not improve the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-NN + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dims after PCA=10, accuracy=90.21%, time=0.4 s\n",
      "dims after PCA=20, accuracy=95.02%, time=0.4 s\n",
      "dims after PCA=30, accuracy=95.65%, time=0.5 s\n",
      "dims after PCA=40, accuracy=95.94%, time=0.5 s\n",
      "dims after PCA=50, accuracy=96.00%, time=0.6 s\n",
      "dims after PCA=60, accuracy=96.02%, time=0.7 s\n",
      "dims after PCA=70, accuracy=95.90%, time=0.8 s\n",
      "dims after PCA=80, accuracy=96.05%, time=0.7 s\n",
      "dims after PCA=90, accuracy=96.05%, time=0.8 s\n",
      "dims after PCA=100, accuracy=96.10%, time=0.9 s\n",
      "dims after PCA=200, accuracy=95.40%, time=1.4 s\n",
      "dims after PCA=300, accuracy=95.38%, time=1.8 s\n",
      "dims after PCA=400, accuracy=95.14%, time=2.6 s\n",
      "dims after PCA=500, accuracy=94.95%, time=3.2 s\n",
      "dims after PCA=600, accuracy=95.00%, time=3.4 s\n"
     ]
    }
   ],
   "source": [
    "dims = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500, 600]\n",
    "\n",
    "# For several values of the k parameter\n",
    "for dim in dims:\n",
    "    \n",
    "    pca = PCA(n_components=dim)\n",
    "    X_train_pca_scaled = pca.fit_transform(X_train_scaled)\n",
    "    X_val_pca_scaled = pca.transform(X_val_scaled)\n",
    "    \n",
    "    # Start timer to report the time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Define a knn classifier with the training data\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=1)\n",
    "    knn_clf.fit(X_train_pca_scaled, y_train)\n",
    "\n",
    "    # Evaluate the model with the test split and print results\n",
    "    acc_knn_clf = knn_clf.score(X_val_pca_scaled, y_val)\n",
    "    print(f\"dims after PCA={dim}, accuracy={acc_knn_clf * 100:.2f}%, time={time.time() - start_time:.1f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 dimensions explain the 95% of accuracy of a K-nn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch for k with 20 dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of neighbors (k): 5\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=20)\n",
    "X_train_pca_scaled = pca.fit_transform(X_train_scaled)\n",
    "X_val_pca_scaled = pca.transform(X_val_scaled)\n",
    "\n",
    "# Set up a parameter grid to search for the best k\n",
    "param_grid = {'n_neighbors': list(range(1, 21))}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "knn_clf = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_pca_scaled, y_train)\n",
    "\n",
    "# Get the best number of neighbors\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "print(f\"Optimal number of neighbors (k): {best_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal k=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nn with optimal k and optimal dimensions of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dims after PCA=90, accuracy=95.22%, time=0.5 s\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=20)\n",
    "X_train_pca_scaled = pca.fit_transform(X_train_scaled)\n",
    "X_val_pca_scaled = pca.transform(X_val_scaled)\n",
    "\n",
    "# Start timer to report the time\n",
    "start_time = time.time()\n",
    "# Define a knn classifier with the training data\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_clf.fit(X_train_pca_scaled, y_train)\n",
    "\n",
    "# Evaluate the model with the test split and print results\n",
    "acc_knn_clf = knn_clf.score(X_val_pca_scaled, y_val)\n",
    "print(f\"dims after PCA=20, accuracy={acc_knn_clf * 100:.2f}%, time={time.time() - start_time:.1f} s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nn with all dimensions and optimal k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-nn with k=5, accuracy=94.75%, time=3.6 s\n"
     ]
    }
   ],
   "source": [
    "# Start timer to report the time\n",
    "start_time = time.time()\n",
    "# Define a knn classifier with the training data\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model with the test split and print results\n",
    "acc_knn_clf = knn_clf.score(X_val_scaled, y_val)\n",
    "print(f\"k-nn with k={best_k}, accuracy={acc_knn_clf * 100:.2f}%, time={time.time() - start_time:.1f} s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poorer performance than without PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, logistic regression: 0.9136507936507936, time=36.6s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Start timer to report the time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit a logistic regression with scaled data\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "acc_lr = lr.score(X_val_scaled, y_val)\n",
    "print(f'Accuracy, logistic classifier: {acc_lr * 100:.2f}, time={time.time() - start_time:.1f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression performs poor than k-nn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with 20 dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, logistic classifier with 20 components of PCA: 87.13, time=4.4s\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=20)\n",
    "X_train_pca_scaled = pca.fit_transform(X_train_scaled)\n",
    "X_val_pca_scaled = pca.transform(X_val_scaled)\n",
    "\n",
    "# Start timer to report the time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit a logistic regression with scaled data\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "lr.fit(X_train_pca_scaled, y_train)\n",
    "acc_lr = lr.score(X_val_pca_scaled, y_val)\n",
    "print(f'Accuracy, logistic classifier with 20 components of PCA: {acc_lr * 100:.2f}, time={time.time() - start_time:.1f}s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Logistic Regression, PCA lowers significantly the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, ridge classifier0.001: 77.06, time=2.6s\n",
      "Accuracy, ridge classifier0.01: 77.06, time=5.1s\n",
      "Accuracy, ridge classifier0.1: 77.06, time=7.5s\n",
      "Accuracy, ridge classifier1: 77.06, time=9.9s\n",
      "Accuracy, ridge classifier10: 77.06, time=12.4s\n",
      "Accuracy, ridge classifier100: 77.06, time=15.9s\n"
     ]
    }
   ],
   "source": [
    "# Fit a ridge classifier for different alphas\n",
    "start_time = time.time()\n",
    "\n",
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for alpha in alphas:\n",
    "    rc = RidgeClassifier(alpha=0.001)\n",
    "    rc.fit(X_train_scaled, y_train)\n",
    "    acc_rc = rc.score(X_val, y_val)\n",
    "    print(f'Accuracy, ridge classifier, alpha={alpha}: {acc_rc * 100:.2f}%, time={time.time() - start_time:.1f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge doesnt pass the threshold for cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with 20 and 30 PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.svm' has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m svm_n \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mSVC(C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m svm_n\u001b[38;5;241m.\u001b[39mfit(X_train_pca_scaled, y_train)\n\u001b[0;32m---> 13\u001b[0m acc_svm_n \u001b[38;5;241m=\u001b[39m \u001b[43msvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m(X_val_pca_scaled, y_val)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy, SVM with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomponent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m components of PCA: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_svm_n\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, time=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn.svm' has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "n_components = [20, 30]\n",
    "for component in n_components:\n",
    "    pca = PCA(component)\n",
    "    X_train_pca_scaled = pca.fit_transform(X_train_scaled)\n",
    "    X_val_pca_scaled = pca.transform(X_val_scaled)\n",
    "\n",
    "    # Start timer to report the time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Fit a SVM classifier\n",
    "    svm_n = svm.SVC(C=1.0,kernel='rbf')\n",
    "    svm_n.fit(X_train_pca_scaled, y_train)\n",
    "    acc_svm_n = svm_n.score(X_val_pca_scaled, y_val)\n",
    "    print(f'Accuracy, SVM with {component} components of PCA: {acc_svm_n * 100:.2f}%, time={time.time() - start_time:.1f}s')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVISEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

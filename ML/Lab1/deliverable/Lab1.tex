\documentclass[twocolumn]{article}
\usepackage[utf8]{inputenc}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e} 
\title{Lab 1 \\ \small Fundamentals of regression and classiÔ¨Åcation.}
\author{David Padilla Orenga\\ Ignacio Pastore Benaim}
\date{\today}   % You can use \date{\today}
\usepackage{biblatex}
\addbibresource{references.bib}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{color}
\usepackage{booktabs}
\usepackage{amsmath}

% Hyphen penalty
\hyphenpenalty=10000
\exhyphenpenalty=10000
\sloppy

\begin{document}

\maketitle

\section{Introduction}


The complete code used for this analysis can be found in a \href{https://colab.research.google.com/drive/1Gg35b8epwsI3nkCeiqCgBeFCd3aNdahI?usp=sharing}{Google Colab Notebook}.

\section{Introduction}

Recordar que

no hice poly2 en gridsearch porque explotaba el computat
SVR lo mismo en el gridsearch
Ademas todos los gridsearchs dan un R2 negativo, por que?
Es mejor separar todos los gridsearc para no tener que volver a correrlos todos
Antes de hacer los gridsearch tengo que hacer test separados para ver si tiene sentid o no.

In this lab, we aim to solve two fundamental machine learning tasks: regression and classification. Both tasks utilize different datasets and methods, and each presents unique challenges in model training and evaluation. For the regression problem, we utilize the \textbf{YearPredictionMSD} dataset, which aims to predict the release year of songs based on a variety of acoustic features. For the classification task, we use the \textbf{CIFAR-10} dataset, a widely recognized dataset for image classification, where the objective is to classify images into one of 10 possible categories.

\subsection{Regression Task}

The \textbf{YearPredictionMSD} dataset consists of over 500,000 examples, each representing a song with a collection of numerical features that describe its acoustic properties. The target variable is the year the song was released. This problem is inherently non-linear and affected by noise, making it an excellent case for testing various regression techniques, including linear regression, polynomial regression, and robust methods like RANSAC and Huber regression. Furthermore, due to the large number of features, dimensionality reduction techniques such as Principal Component Analysis (PCA) are explored to improve computational efficiency and model performance.

\subsection{Classification Task}

For the classification task, we work with the \textbf{CIFAR-10} dataset, which consists of 60,000 32x32 color images from 10 different classes (e.g., airplanes, cats, cars, etc.). Each image is represented as a feature vector of pixel values. The objective is to classify these images accurately into their respective categories using models such as k-Nearest Neighbors (k-NN), Support Vector Machines (SVM), and Voting Classifiers. Dimensionality reduction is again considered through PCA to speed up training, particularly for computationally intensive models like SVM.

Both tasks involve model selection, hyperparameter tuning, and evaluation using appropriate metrics. In regression, we will use metrics such as Mean Squared Error (MSE) and the Median Absolute Error (MedAE), which is robust to outliers. For classification, accuracy, precision, recall, and F1-score will be employed to measure model performance. Through this lab, we aim to gain a deeper understanding of model behavior in different scenarios and explore techniques to address the challenges presented by high-dimensional and noisy data.

\end{document}

 
\end{document}


